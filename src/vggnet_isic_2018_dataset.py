# -*- coding: utf-8 -*-
"""VGGNet ISIC 2018 dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D-wkrlPkqXCCzxKjBrikQZZNY0Rktotm
"""

import os
import sys
import time
import pickle
import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from tqdm import tqdm_notebook as tqdm
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, Input
from keras.models import Model, load_model
from keras.utils import to_categorical
from keras.optimizers import SGD, RMSprop
from keras.applications.vgg16 import VGG16, preprocess_input

drive_base_path = "/content/gdrive/My Drive/Minor Project/"
path_to_images = drive_base_path + "dataset/ISIC2018_Training_Input/"
path_to_image_aug = drive_base_path + "dataset/ISIC2018_VGG16_Training_AUG/"
path_to_description = drive_base_path + "dataset/ISIC2018_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv"

def create_train_test(path_to_images, path_to_description, test_split=0.0):
    X_train = []
    y_train = []
    X_test = []
    y_test = []

    input_size = 224
    list_of_images = os.listdir(path_to_images)
    number = len(list_of_images)

    for filename in tqdm(list_of_images, total=number):
        image = cv2.imread(path_to_images + filename)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        old_size = image.shape[:2]

        ratio = float(input_size)/max(old_size)
        new_size = tuple([int(x * ratio) for x in old_size])

        image = cv2.resize(image, (new_size[1], new_size[0]))

        delta_w = input_size - new_size[1]
        delta_h = input_size - new_size[0]
        top, bottom = delta_h//2, delta_h-(delta_h//2)
        left, right = delta_w//2, delta_w-(delta_w//2)

        color = [0, 0, 0]
        new_img = cv2.copyMakeBorder(image, top, bottom, left, right,
                                     cv2.BORDER_CONSTANT, value=color)

        X_train.append(new_img)

        with open(path_to_description, "r") as file:
            for line in file:
                row = line.rstrip("\n").split(",")
                if row[0] == filename[0:-4]:
                    y_train.append([int(float(x)) for x in row[1:]])

    X_train = np.array(X_train)
    y_train = np.array(y_train)
    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_split, random_state=42)
    return (X_train, X_test, y_train, y_test)

# X_train, X_test, y_train, y_test = create_train_test(path_to_images, path_to_description)

# with open(drive_base_path + "dataset/pickled-data/VGG16_ISIC_2018_data.pkl", "wb") as file:
#     pickle.dump((X_train, X_test, y_train, y_test), file)

with open(drive_base_path + "dataset/pickled-data/VGG16_ISIC_2018_data.pkl", "rb") as file:
    X_train, X_test, y_train, y_test = pickle.load(file)

datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    data_format="channels_last")

datagen.fit(X_train[2000:3000])

# x, y = next(datagen.flow(X_train, y_train, save_to_dir=path_to_image_aug))

print("Training X Size", X_train.shape)
print("Training Y Size (Melanoma, Melanocytic Nevus, Basal Cell Carcinoma, Actinic Keratosis, Benign Keratosis, Dermatofiroma, Vascular Lesion)", y_train.shape)
for i in range(5):
    print(X_train[i].shape, y_train[i])

base_model = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))

x = base_model.output
x = Flatten()(x)
x = Dense(4096, activation='relu')(x)
x = Dense(4096, activation='relu')(x)
predictions = Dense(7, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

for layer in base_model.layers:
    layer.trainable = False

# for layer in model.layers:
#     print(layer, layer.trainable)

model.compile(loss="categorical_crossentropy",
              optimizer=RMSprop(lr=1e-4),
              metrics=["accuracy"])
# print(model.summary())

batch_size = 32
epochs = 2
history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train) / batch_size, epochs=epochs, verbose=1, shuffle=True)

for i, layer in enumerate(model.layers):
    print(i, layer.name)

for layer in model.layers[:15]:
    layer.trainable = False
for layer in model.layers[15:]:
    layer.trainable = True

# for layer in model.layers:
#     print(layer, layer.trainable)

model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=["accuracy"])
epochs = 10
batch_size = 32
history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),
                              steps_per_epoch=len(X_train) / batch_size,
                              epochs=epochs, verbose=1,
                              shuffle=True)
model.save_weights(drive_base_path + 'models/VGG16_ISIC_cnn.h5')
# model.evaluate(X_test, y_test)

# Plot Training and Validation Accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# TESTTING ON ISIC LIVE IMAGE DATA
"""
path_to_images = drive_base_path + "dataset/ISIC2018_Task3_Validation_Input/"

list_of_images = os.listdir(path_to_images)
filename = list_of_images[0]
print(filename[:-4])
input_size = 224

image = cv2.imread(path_to_images + filename)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
old_size = image.shape[:2]

ratio = float(input_size)/max(old_size)
new_size = tuple([int(x * ratio) for x in old_size])

image = cv2.resize(image, (new_size[1], new_size[0]))

delta_w = input_size - new_size[1]
delta_h = input_size - new_size[0]
top, bottom = delta_h//2, delta_h-(delta_h//2)
left, right = delta_w//2, delta_w-(delta_w//2)

color = [0, 0, 0]
new_img = cv2.copyMakeBorder(image, top, bottom, left, right,
                             cv2.BORDER_CONSTANT, value=color)

plt.imshow(new_img)

def preprocess_images(path_to_images):
    images_list = []
    filename_list = []

    input_size = 224
    list_of_images = os.listdir(path_to_images)
    number = len(list_of_images)

    for filename in tqdm(list_of_images, total=number):
        filename_list.append(filename[:-4])

        image = cv2.imread(path_to_images + filename)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        old_size = image.shape[:2]

        ratio = float(input_size)/max(old_size)
        new_size = tuple([int(x * ratio) for x in old_size])

        image = cv2.resize(image, (new_size[1], new_size[0]))

        delta_w = input_size - new_size[1]
        delta_h = input_size - new_size[0]
        top, bottom = delta_h//2, delta_h-(delta_h//2)
        left, right = delta_w//2, delta_w-(delta_w//2)

        color = [0, 0, 0]
        new_img = cv2.copyMakeBorder(image, top, bottom, left, right,
                                     cv2.BORDER_CONSTANT, value=color)

#         arr = np.array(image)
        images_list.append(new_img)

    images_list = np.array(images_list)
    filename_list = np.array(filename_list)
    filename_list = filename_list[:, None]
    return (images_list, filename_list)

x, names = preprocess_images(path_to_images)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=0,
    width_shift_range=0.0,
    height_shift_range=0.0,
    horizontal_flip=False,
    rescale=1. /255.,
    fill_mode='nearest',
    data_format="channels_last",
    shuffle=False)

datagen.fit(x)

print("X Shape", x.shape)
plt.imshow(x[60])
print("Name Shape", names.shape)

model.load_weights(drive_base_path + 'models/VGG16_ISIC_cnn.h5')

predictions = model.predict_generator(datagen.flow(x, batch_size=1))
classes = (predictions > 0.5).astype(np.float)
print(classes.shape)

final_output = np.concatenate((names, classes), axis=1)
final_output.shape

import csv

with open("output.csv", "w") as f:
    writer = csv.writer(f)
    writer.writerow(["image", "MEL", "NV", "BCC", "AKIEC", "BKL", "DF", "VASC"])
    writer.writerows(final_output)

"""
