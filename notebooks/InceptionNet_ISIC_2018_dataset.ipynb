{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "YLzijiJ8Ug_L",
    "outputId": "a57ce5c2-855d-4c53-f3cb-4cbc6ec446df"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, Input, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhfXVzhAUtzz"
   },
   "outputs": [],
   "source": [
    "drive_base_path = \"../\"\n",
    "path_to_images = drive_base_path + \"dataset/ISIC2018_Balanced_Training_Input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F33x1VYeXZ1"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\n",
    "train_generator = datagen.flow_from_directory(\n",
    "                    directory=path_to_images,\n",
    "                    target_size=(299, 299),\n",
    "                    batch_size=32,\n",
    "                    classes=classes,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12328
    },
    "colab_type": "code",
    "id": "vl5cpn4gUxgq",
    "outputId": "614c23d4-9a4b-4ede-f383-3423287f6764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 149, 149, 32) 96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 149, 149, 32) 0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 147, 147, 32) 9216        activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 147, 147, 32) 96          conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 147, 147, 32) 0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 147, 147, 64) 18432       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 147, 147, 64) 192         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 147, 147, 64) 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 73, 73, 64)   0           activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 73, 73, 80)   240         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 73, 73, 80)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 71, 71, 192)  138240      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 71, 71, 192)  576         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 71, 71, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 35, 35, 192)  0           activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 35, 35, 64)   192         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 35, 35, 64)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 35, 35, 96)   55296       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 35, 35, 48)   144         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 35, 35, 48)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 35, 35, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 35, 35, 64)   76800       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 35, 35, 96)   82944       activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 35, 35, 64)   192         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 35, 35, 96)   288         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 35, 35, 32)   96          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 35, 35, 64)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 35, 35, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 35, 35, 96)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 35, 35, 32)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_288[0][0]             \n",
      "                                                                 activation_290[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "                                                                 activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 35, 35, 64)   192         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 35, 35, 64)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 35, 35, 96)   55296       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 35, 35, 48)   144         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 35, 35, 48)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 35, 35, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 35, 35, 64)   76800       activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 35, 35, 96)   82944       activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 35, 35, 64)   192         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 35, 35, 96)   288         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 35, 35, 64)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 35, 35, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 35, 35, 96)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 35, 35, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_295[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 35, 35, 64)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 35, 35, 48)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 35, 35, 64)   192         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 35, 35, 64)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 35, 35, 96)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 35, 35, 64)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_302[0][0]             \n",
      "                                                                 activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "                                                                 activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 35, 35, 64)   192         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 35, 35, 64)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 35, 35, 96)   55296       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 35, 35, 96)   288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 35, 35, 96)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 17, 17, 96)   82944       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 17, 17, 384)  1152        conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 17, 17, 96)   288         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 17, 17, 384)  0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 17, 17, 96)   0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_309[0][0]             \n",
      "                                                                 activation_312[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 17, 17, 128)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 17, 17, 128)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 17, 17, 128)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 17, 17, 128)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 17, 17, 128)  114688      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 17, 17, 128)  114688      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 17, 17, 128)  384         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 17, 17, 128)  0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 17, 17, 128)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 17, 17, 192)  172032      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 17, 17, 192)  172032      activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 17, 17, 192)  576         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 17, 17, 192)  576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 17, 17, 192)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 17, 17, 192)  0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 17, 17, 192)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_313[0][0]             \n",
      "                                                                 activation_316[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 17, 17, 160)  0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 17, 17, 160)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 17, 17, 160)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 17, 17, 160)  179200      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 17, 17, 160)  179200      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 17, 17, 160)  480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 17, 17, 160)  0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 17, 17, 160)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 17, 17, 192)  215040      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 17, 17, 192)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 17, 17, 192)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 17, 17, 192)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_323[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "                                                                 activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 17, 17, 160)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 17, 17, 160)  179200      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 17, 17, 160)  179200      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 17, 17, 160)  480         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 17, 17, 160)  480         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 17, 17, 160)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 17, 17, 160)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 17, 17, 192)  215040      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 17, 17, 192)  215040      activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 17, 17, 192)  576         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 17, 17, 192)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 17, 17, 192)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 17, 17, 192)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_333[0][0]             \n",
      "                                                                 activation_336[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 17, 17, 192)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 17, 17, 192)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 17, 17, 192)  258048      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 17, 17, 192)  258048      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 17, 17, 192)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_343[0][0]             \n",
      "                                                                 activation_346[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "                                                                 activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 17, 17, 192)  258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 17, 17, 192)  0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 17, 17, 192)  258048      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 17, 17, 192)  576         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 17, 17, 192)  576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 17, 17, 192)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 17, 17, 192)  0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 8, 8, 320)    552960      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 8, 8, 192)    331776      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 8, 8, 320)    960         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 8, 8, 192)    576         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 8, 8, 320)    0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 8, 8, 192)    0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_354[0][0]             \n",
      "                                                                 activation_358[0][0]             \n",
      "                                                                 max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 8, 8, 448)    1344        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 8, 8, 448)    0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 8, 8, 384)    1548288     activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 8, 8, 384)    1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 8, 8, 384)    0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 8, 8, 384)    0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 8, 8, 384)    1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 8, 8, 384)    1152        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 8, 8, 384)    1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 8, 8, 384)    1152        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 8, 8, 320)    960         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 8, 8, 384)    0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 8, 8, 384)    0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 8, 8, 384)    0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 8, 8, 384)    0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 8, 8, 192)    576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 8, 8, 320)    0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_361[0][0]             \n",
      "                                                                 activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 768)    0           activation_365[0][0]             \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 8, 8, 192)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_359[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 8, 8, 448)    1344        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 8, 8, 448)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 8, 8, 384)    1548288     activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 8, 8, 384)    1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 8, 8, 384)    1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 8, 8, 384)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 8, 8, 384)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 8, 8, 384)    1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 8, 8, 384)    1152        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 8, 8, 384)    1152        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 8, 8, 320)    960         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 8, 8, 384)    0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 8, 8, 384)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 8, 8, 384)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 8, 8, 384)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 8, 8, 192)    576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 8, 8, 320)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_370[0][0]             \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 768)    0           activation_374[0][0]             \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 8, 8, 192)    0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_368[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 7)            14343       dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,013,479\n",
      "Trainable params: 4,210,695\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(299, 299, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=1e-5), metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFYDOqZUVJ-_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "313/312 [==============================] - 70s 222ms/step - loss: 1.0168 - acc: 0.6703\n",
      "Epoch 2/2\n",
      "313/312 [==============================] - 61s 196ms/step - loss: 0.8884 - acc: 0.6898\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "history = model.fit_generator(train_generator, \n",
    "                              epochs=epochs,\n",
    "                              class_weight=class_weights,\n",
    "                              steps_per_epoch=520,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5219
    },
    "colab_type": "code",
    "id": "27O47zTNVKSM",
    "outputId": "c76a08c5-98a0-4f92-8225-d3c68f8103b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_4\n",
      "1 conv2d_283\n",
      "2 batch_normalization_283\n",
      "3 activation_283\n",
      "4 conv2d_284\n",
      "5 batch_normalization_284\n",
      "6 activation_284\n",
      "7 conv2d_285\n",
      "8 batch_normalization_285\n",
      "9 activation_285\n",
      "10 max_pooling2d_13\n",
      "11 conv2d_286\n",
      "12 batch_normalization_286\n",
      "13 activation_286\n",
      "14 conv2d_287\n",
      "15 batch_normalization_287\n",
      "16 activation_287\n",
      "17 max_pooling2d_14\n",
      "18 conv2d_291\n",
      "19 batch_normalization_291\n",
      "20 activation_291\n",
      "21 conv2d_289\n",
      "22 conv2d_292\n",
      "23 batch_normalization_289\n",
      "24 batch_normalization_292\n",
      "25 activation_289\n",
      "26 activation_292\n",
      "27 average_pooling2d_28\n",
      "28 conv2d_288\n",
      "29 conv2d_290\n",
      "30 conv2d_293\n",
      "31 conv2d_294\n",
      "32 batch_normalization_288\n",
      "33 batch_normalization_290\n",
      "34 batch_normalization_293\n",
      "35 batch_normalization_294\n",
      "36 activation_288\n",
      "37 activation_290\n",
      "38 activation_293\n",
      "39 activation_294\n",
      "40 mixed0\n",
      "41 conv2d_298\n",
      "42 batch_normalization_298\n",
      "43 activation_298\n",
      "44 conv2d_296\n",
      "45 conv2d_299\n",
      "46 batch_normalization_296\n",
      "47 batch_normalization_299\n",
      "48 activation_296\n",
      "49 activation_299\n",
      "50 average_pooling2d_29\n",
      "51 conv2d_295\n",
      "52 conv2d_297\n",
      "53 conv2d_300\n",
      "54 conv2d_301\n",
      "55 batch_normalization_295\n",
      "56 batch_normalization_297\n",
      "57 batch_normalization_300\n",
      "58 batch_normalization_301\n",
      "59 activation_295\n",
      "60 activation_297\n",
      "61 activation_300\n",
      "62 activation_301\n",
      "63 mixed1\n",
      "64 conv2d_305\n",
      "65 batch_normalization_305\n",
      "66 activation_305\n",
      "67 conv2d_303\n",
      "68 conv2d_306\n",
      "69 batch_normalization_303\n",
      "70 batch_normalization_306\n",
      "71 activation_303\n",
      "72 activation_306\n",
      "73 average_pooling2d_30\n",
      "74 conv2d_302\n",
      "75 conv2d_304\n",
      "76 conv2d_307\n",
      "77 conv2d_308\n",
      "78 batch_normalization_302\n",
      "79 batch_normalization_304\n",
      "80 batch_normalization_307\n",
      "81 batch_normalization_308\n",
      "82 activation_302\n",
      "83 activation_304\n",
      "84 activation_307\n",
      "85 activation_308\n",
      "86 mixed2\n",
      "87 conv2d_310\n",
      "88 batch_normalization_310\n",
      "89 activation_310\n",
      "90 conv2d_311\n",
      "91 batch_normalization_311\n",
      "92 activation_311\n",
      "93 conv2d_309\n",
      "94 conv2d_312\n",
      "95 batch_normalization_309\n",
      "96 batch_normalization_312\n",
      "97 activation_309\n",
      "98 activation_312\n",
      "99 max_pooling2d_15\n",
      "100 mixed3\n",
      "101 conv2d_317\n",
      "102 batch_normalization_317\n",
      "103 activation_317\n",
      "104 conv2d_318\n",
      "105 batch_normalization_318\n",
      "106 activation_318\n",
      "107 conv2d_314\n",
      "108 conv2d_319\n",
      "109 batch_normalization_314\n",
      "110 batch_normalization_319\n",
      "111 activation_314\n",
      "112 activation_319\n",
      "113 conv2d_315\n",
      "114 conv2d_320\n",
      "115 batch_normalization_315\n",
      "116 batch_normalization_320\n",
      "117 activation_315\n",
      "118 activation_320\n",
      "119 average_pooling2d_31\n",
      "120 conv2d_313\n",
      "121 conv2d_316\n",
      "122 conv2d_321\n",
      "123 conv2d_322\n",
      "124 batch_normalization_313\n",
      "125 batch_normalization_316\n",
      "126 batch_normalization_321\n",
      "127 batch_normalization_322\n",
      "128 activation_313\n",
      "129 activation_316\n",
      "130 activation_321\n",
      "131 activation_322\n",
      "132 mixed4\n",
      "133 conv2d_327\n",
      "134 batch_normalization_327\n",
      "135 activation_327\n",
      "136 conv2d_328\n",
      "137 batch_normalization_328\n",
      "138 activation_328\n",
      "139 conv2d_324\n",
      "140 conv2d_329\n",
      "141 batch_normalization_324\n",
      "142 batch_normalization_329\n",
      "143 activation_324\n",
      "144 activation_329\n",
      "145 conv2d_325\n",
      "146 conv2d_330\n",
      "147 batch_normalization_325\n",
      "148 batch_normalization_330\n",
      "149 activation_325\n",
      "150 activation_330\n",
      "151 average_pooling2d_32\n",
      "152 conv2d_323\n",
      "153 conv2d_326\n",
      "154 conv2d_331\n",
      "155 conv2d_332\n",
      "156 batch_normalization_323\n",
      "157 batch_normalization_326\n",
      "158 batch_normalization_331\n",
      "159 batch_normalization_332\n",
      "160 activation_323\n",
      "161 activation_326\n",
      "162 activation_331\n",
      "163 activation_332\n",
      "164 mixed5\n",
      "165 conv2d_337\n",
      "166 batch_normalization_337\n",
      "167 activation_337\n",
      "168 conv2d_338\n",
      "169 batch_normalization_338\n",
      "170 activation_338\n",
      "171 conv2d_334\n",
      "172 conv2d_339\n",
      "173 batch_normalization_334\n",
      "174 batch_normalization_339\n",
      "175 activation_334\n",
      "176 activation_339\n",
      "177 conv2d_335\n",
      "178 conv2d_340\n",
      "179 batch_normalization_335\n",
      "180 batch_normalization_340\n",
      "181 activation_335\n",
      "182 activation_340\n",
      "183 average_pooling2d_33\n",
      "184 conv2d_333\n",
      "185 conv2d_336\n",
      "186 conv2d_341\n",
      "187 conv2d_342\n",
      "188 batch_normalization_333\n",
      "189 batch_normalization_336\n",
      "190 batch_normalization_341\n",
      "191 batch_normalization_342\n",
      "192 activation_333\n",
      "193 activation_336\n",
      "194 activation_341\n",
      "195 activation_342\n",
      "196 mixed6\n",
      "197 conv2d_347\n",
      "198 batch_normalization_347\n",
      "199 activation_347\n",
      "200 conv2d_348\n",
      "201 batch_normalization_348\n",
      "202 activation_348\n",
      "203 conv2d_344\n",
      "204 conv2d_349\n",
      "205 batch_normalization_344\n",
      "206 batch_normalization_349\n",
      "207 activation_344\n",
      "208 activation_349\n",
      "209 conv2d_345\n",
      "210 conv2d_350\n",
      "211 batch_normalization_345\n",
      "212 batch_normalization_350\n",
      "213 activation_345\n",
      "214 activation_350\n",
      "215 average_pooling2d_34\n",
      "216 conv2d_343\n",
      "217 conv2d_346\n",
      "218 conv2d_351\n",
      "219 conv2d_352\n",
      "220 batch_normalization_343\n",
      "221 batch_normalization_346\n",
      "222 batch_normalization_351\n",
      "223 batch_normalization_352\n",
      "224 activation_343\n",
      "225 activation_346\n",
      "226 activation_351\n",
      "227 activation_352\n",
      "228 mixed7\n",
      "229 conv2d_355\n",
      "230 batch_normalization_355\n",
      "231 activation_355\n",
      "232 conv2d_356\n",
      "233 batch_normalization_356\n",
      "234 activation_356\n",
      "235 conv2d_353\n",
      "236 conv2d_357\n",
      "237 batch_normalization_353\n",
      "238 batch_normalization_357\n",
      "239 activation_353\n",
      "240 activation_357\n",
      "241 conv2d_354\n",
      "242 conv2d_358\n",
      "243 batch_normalization_354\n",
      "244 batch_normalization_358\n",
      "245 activation_354\n",
      "246 activation_358\n",
      "247 max_pooling2d_16\n",
      "248 mixed8\n",
      "249 conv2d_363\n",
      "250 batch_normalization_363\n",
      "251 activation_363\n",
      "252 conv2d_360\n",
      "253 conv2d_364\n",
      "254 batch_normalization_360\n",
      "255 batch_normalization_364\n",
      "256 activation_360\n",
      "257 activation_364\n",
      "258 conv2d_361\n",
      "259 conv2d_362\n",
      "260 conv2d_365\n",
      "261 conv2d_366\n",
      "262 average_pooling2d_35\n",
      "263 conv2d_359\n",
      "264 batch_normalization_361\n",
      "265 batch_normalization_362\n",
      "266 batch_normalization_365\n",
      "267 batch_normalization_366\n",
      "268 conv2d_367\n",
      "269 batch_normalization_359\n",
      "270 activation_361\n",
      "271 activation_362\n",
      "272 activation_365\n",
      "273 activation_366\n",
      "274 batch_normalization_367\n",
      "275 activation_359\n",
      "276 mixed9_0\n",
      "277 concatenate_7\n",
      "278 activation_367\n",
      "279 mixed9\n",
      "280 conv2d_372\n",
      "281 batch_normalization_372\n",
      "282 activation_372\n",
      "283 conv2d_369\n",
      "284 conv2d_373\n",
      "285 batch_normalization_369\n",
      "286 batch_normalization_373\n",
      "287 activation_369\n",
      "288 activation_373\n",
      "289 conv2d_370\n",
      "290 conv2d_371\n",
      "291 conv2d_374\n",
      "292 conv2d_375\n",
      "293 average_pooling2d_36\n",
      "294 conv2d_368\n",
      "295 batch_normalization_370\n",
      "296 batch_normalization_371\n",
      "297 batch_normalization_374\n",
      "298 batch_normalization_375\n",
      "299 conv2d_376\n",
      "300 batch_normalization_368\n",
      "301 activation_370\n",
      "302 activation_371\n",
      "303 activation_374\n",
      "304 activation_375\n",
      "305 batch_normalization_376\n",
      "306 activation_368\n",
      "307 mixed9_1\n",
      "308 concatenate_8\n",
      "309 activation_376\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1135
    },
    "colab_type": "code",
    "id": "1t9sZHnUVKj3",
    "outputId": "f56af482-71ba-428b-c4ad-ede261dffd05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/312 [==============================] - 86s 275ms/step - loss: 0.8481 - acc: 0.7053\n",
      "Epoch 2/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 0.8455 - acc: 0.7050\n",
      "Epoch 3/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 0.8710 - acc: 0.6960\n",
      "Epoch 4/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.0418 - acc: 0.6705\n",
      "Epoch 5/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.1316 - acc: 0.6695\n",
      "Epoch 6/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.1315 - acc: 0.6695\n",
      "Epoch 7/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.1315 - acc: 0.6695\n",
      "Epoch 8/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.1316 - acc: 0.6695\n",
      "Epoch 9/10\n",
      "313/312 [==============================] - 76s 242ms/step - loss: 1.1314 - acc: 0.6695\n",
      "Epoch 10/10\n",
      "116/312 [==========>...................] - ETA: 47s - loss: 1.1274 - acc: 0.6691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fdbc486d7d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               shuffle=True)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_base_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'models/InceptionV3Net_ISIC_cnn.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    488\u001b[0m       if (isinstance(fetch, ops.Tensor) and\n\u001b[1;32m    489\u001b[0m           (fetch.op.type == 'GetSessionHandle' or\n\u001b[0;32m--> 490\u001b[0;31m            fetch.op.type == 'GetSessionHandleV2')):\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(lr=1e-5, momentum=0.9), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=520,\n",
    "                              epochs=epochs,\n",
    "                              class_weight=class_weights,\n",
    "                              verbose=1)\n",
    "model.save_weights(drive_base_path + 'models/InceptionV3Net_ISIC_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY AND LOSS PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97kUVOthVK0Y"
   },
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_test = y_train[:500]\n",
    "X_test = X_train[:500]\n",
    "\n",
    "y_pred = model.predict_generator(datagen.flow(X_test, batch_size=1), steps=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(np.int)\n",
    "y_test = y_test.argmax(axis=1)\n",
    "y_pred = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC LIVE IMAGE TEST/VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wE4hWz7e2nd"
   },
   "outputs": [],
   "source": [
    "path_to_images = drive_base_path + \"dataset/ISIC2018_Task3_Validation_Input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuljCuiMe2cU"
   },
   "outputs": [],
   "source": [
    "list_of_images = os.listdir(path_to_images)\n",
    "filename = list_of_images[0]\n",
    "print(filename[:-4])\n",
    "input_size = 224\n",
    "\n",
    "image = cv2.imread(path_to_images + filename)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "old_size = image.shape[:2]\n",
    "\n",
    "ratio = float(input_size)/max(old_size)\n",
    "new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "delta_w = input_size - new_size[1]\n",
    "delta_h = input_size - new_size[0]\n",
    "top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "color = [0, 0, 0]\n",
    "new_img = cv2.copyMakeBorder(image, top, bottom, left, right, \n",
    "                             cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "plt.imshow(new_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYc7Y-u1e2Wi"
   },
   "outputs": [],
   "source": [
    "def preprocess_images(path_to_images):\n",
    "    images_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    input_size = 224\n",
    "    list_of_images = os.listdir(path_to_images)\n",
    "    number = len(list_of_images)\n",
    "    \n",
    "    for filename in tqdm(list_of_images, total=number):\n",
    "        filename_list.append(filename[:-4])\n",
    "        \n",
    "        image = cv2.imread(path_to_images + filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        old_size = image.shape[:2]\n",
    "        \n",
    "        ratio = float(input_size)/max(old_size)\n",
    "        new_size = tuple([int(x * ratio) for x in old_size])\n",
    "        \n",
    "        image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "        \n",
    "        delta_w = input_size - new_size[1]\n",
    "        delta_h = input_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        \n",
    "        color = [0, 0, 0]\n",
    "        new_img = cv2.copyMakeBorder(image, top, bottom, left, right, \n",
    "                                     cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "#         arr = np.array(image)\n",
    "        images_list.append(new_img)\n",
    "        \n",
    "    images_list = np.array(images_list)\n",
    "    filename_list = np.array(filename_list)\n",
    "    filename_list = filename_list[:, None]\n",
    "    return (images_list, filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tifro4de2Pb"
   },
   "outputs": [],
   "source": [
    "x, names = preprocess_images(path_to_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6qY3lcre2EY"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    horizontal_flip=False,\n",
    "    rescale=1. /255.,\n",
    "    fill_mode='nearest',\n",
    "    data_format=\"channels_last\",\n",
    "    shuffle=False)\n",
    "\n",
    "datagen.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Bds3W0de85l"
   },
   "outputs": [],
   "source": [
    "print(\"X Shape\", x.shape)\n",
    "plt.imshow(x[60])\n",
    "print(\"Name Shape\", names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-yT49TSe8yu"
   },
   "outputs": [],
   "source": [
    "model.load_weights(drive_base_path + 'models/InceptionV3Net_ISIC_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44ZxR1LkfAx8"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(datagen.flow(x, batch_size=1))\n",
    "classes = (predictions > 0.5).astype(np.float)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ru3CoYaKfAq4"
   },
   "outputs": [],
   "source": [
    "final_output = np.concatenate((names, classes), axis=1)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuIB0fAGfAii"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"output.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"image\", \"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"])\n",
    "    writer.writerows(final_output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionNet ISIC 2018 dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
