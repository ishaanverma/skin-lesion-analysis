{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_base_path = \"../\"\n",
    "path_to_images = drive_base_path + \"dataset/ISIC2018_Training_Input/\"\n",
    "path_to_balanced_images = drive_base_path + \"dataset/Balanced_Training_Input_Aug/\"\n",
    "path_to_image_save = drive_base_path + \"dataset/sample_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"VGG19_%s\" % (int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='./logs/%s' % (NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = drive_base_path + \"models/checkpoint/VGG19.{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(path_to_images, number_of_images):\n",
    "    list_of_images = os.listdir(path_to_images)\n",
    "    x = []\n",
    "    for i, filename in enumerate(list_of_images):\n",
    "        image = cv2.imread(path_to_images + filename)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        x.append(image)\n",
    "        \n",
    "        if i >= number_of_images:\n",
    "            break\n",
    "    \n",
    "    x = np.array(x)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_sample(path_to_images, 1000)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    "    validation_split=0.1,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\n",
    "batch_size = 16\n",
    "train_generator = datagen.flow_from_directory(\n",
    "                    directory=path_to_balanced_images,\n",
    "                    target_size=(224, 224),\n",
    "                    batch_size=batch_size,\n",
    "                    classes=classes,\n",
    "                    shuffle=True,\n",
    "                    subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "                    directory=path_to_balanced_images,\n",
    "                    target_size=(224, 224),\n",
    "                    batch_size=batch_size,\n",
    "                    classes=classes,\n",
    "                    shuffle=True,\n",
    "                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train_generator.samples\n",
    "valid_samples = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, \n",
    "          kernel_regularizer=regularizers.l2(5e-4),\n",
    "          activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, \n",
    "          kernel_regularizer=regularizers.l2(5e-4),\n",
    "          activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     print(layer, layer.trainable)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=RMSprop(lr=1e-5), \n",
    "              metrics=[\"acc\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=train_samples / batch_size,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=valid_samples / batch_size,\n",
    "                              epochs=epochs,\n",
    "#                               class_weight=class_weights,\n",
    "                              verbose=1,\n",
    "                              callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = drive_base_path + \"models/checkpoint/VGG16.06-0.62.hdf5\"\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"VGG16_%s\" % (int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='./logs/%s' % (NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=train_samples / batch_size,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=valid_samples / batch_size,\n",
    "                              epochs=epochs,\n",
    "#                               class_weight=class_weights,\n",
    "                              verbose=1,\n",
    "                              callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name)\n",
    "\n",
    "for layer in model.layers[:11]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[11:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = drive_base_path + \"models/checkpoint/VGG119.03-0.64.hdf5\"\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = drive_base_path + \"models/checkpoint/VGG19_REST.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"VGG19_REST_%s\" % (int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='./logs/%s' % (NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=1e-4, momentum=0.9), loss='categorical_crossentropy', metrics=[\"acc\"])\n",
    "epochs = 15\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch=train_samples / batch_size,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=valid_samples / batch_size,\n",
    "#                               class_weight=class_weights,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=[tensorboard, checkpoint])\n",
    "model.save_weights(drive_base_path + 'models/VGG19_AUG_ISIC_cnn.h5')\n",
    "# model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY AND LOSS PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training and Validation Accuracy\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['mel', 'nv', 'bcc', 'akiec', 'bkl', 'df', 'vasc']\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "                    directory=path_to_balanced_images,\n",
    "                    target_size=(224, 224),\n",
    "                    batch_size=1,\n",
    "                    classes=classes,\n",
    "                    shuffle=False,\n",
    "                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = drive_base_path + \"models/checkpoint/VGG19_REST.15-1.05.hdf5\"\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, steps=valid_samples / 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "plot_confusion_matrix(validation_generator.classes, y_pred, classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC LIVE IMAGE TEST/VALIDATION DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTTING ON ISIC LIVE IMAGE DATA\n",
    "path_to_images = drive_base_path + \"dataset/ISIC2018_Task3_Test_Input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(path_to_images):\n",
    "    images_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    path_to_images = path_to_images + 'test/'\n",
    "    \n",
    "    input_size = 224\n",
    "    list_of_images = os.listdir(path_to_images)\n",
    "    number = len(list_of_images)\n",
    "    \n",
    "    for filename in tqdm(list_of_images, total=number):\n",
    "        filename_list.append(filename[:-4])\n",
    "        \n",
    "        image = cv2.imread(path_to_images + filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        old_size = image.shape[:2] # height, width\n",
    "\n",
    "        ratio = float(input_size)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "        image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "        delta_w = input_size - new_size[1]\n",
    "        delta_h = input_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        new_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, \n",
    "                                    value=color)\n",
    "\n",
    "        images_list.append(new_img)\n",
    "        \n",
    "    images_list = np.array(images_list)\n",
    "    filename_list = np.array(filename_list)\n",
    "    filename_list = filename_list[:, None]\n",
    "    return (images_list, filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, names = preprocess_images(path_to_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(names.shape)\n",
    "plt.imshow(x_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = datagen.flow(\n",
    "                    x_test,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(drive_base_path + 'models/VGG19_AUG_ISIC_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator, steps=len(x_test))\n",
    "# classes = (predictions > 0.5).astype(np.float)\n",
    "# print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = np.concatenate((names, predictions), axis=1)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(drive_base_path + \"output.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"image\", \"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"])\n",
    "    writer.writerows(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
